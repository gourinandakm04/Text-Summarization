# -*- coding: utf-8 -*-
"""Text summarizer .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SuSIUbV4R-NF5GwOn3Z8uH66K1n4Ah05
"""

# Create a sample text file
article_text = """
In recent news, technology companies are continuously advancing AI and machine learning.
The development of new algorithms is transforming industries, from healthcare to finance.
Companies like Google, Microsoft, and OpenAI are leading the charge in AI research, and
the potential applications are vast.
"""

# Write the article text to a file
with open("article.txt", "w", encoding="utf8") as f:
    f.write(article_text)

# Now, read and summarize the text
with open("article.txt", "r", encoding="utf8") as f:
    article_text = f.read()

print(article_text)

import transformers
from transformers import pipeline
# Initialize the summarizer pipeline with a suitable model
summarizer = pipeline("summarization", model="facebook/bart-large-cnn")

# Read the article text from the file
with open("article.txt", "r", encoding="utf8") as f:
    article_text = f.read()

# Check if the article is too long and split it into chunks if necessary
max_input_length = 1024  # BART model's token limit

# Split the article into smaller chunks if it's too long
chunks = [article_text[i:i + max_input_length] for i in range(0, len(article_text), max_input_length)]

# Summarize each chunk and combine the results
summarized_text = ""
for chunk in chunks:
    summarized_chunk = summarizer(chunk, min_length=75, max_length=300)
    summarized_text += summarized_chunk[0]['summary_text'] + " "

# Print the summarized text
print(summarized_text)

