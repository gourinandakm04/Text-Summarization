{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP81jsf+5PyrlkrXGEcYzF9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gourinandakm04/Text-Summarization/blob/main/Text_summarizer_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sample text file\n",
        "article_text = \"\"\"\n",
        "In recent news, technology companies are continuously advancing AI and machine learning.\n",
        "The development of new algorithms is transforming industries, from healthcare to finance.\n",
        "Companies like Google, Microsoft, and OpenAI are leading the charge in AI research, and\n",
        "the potential applications are vast.\n",
        "\"\"\"\n",
        "\n",
        "# Write the article text to a file\n",
        "with open(\"article.txt\", \"w\", encoding=\"utf8\") as f:\n",
        "    f.write(article_text)\n",
        "\n",
        "# Now, read and summarize the text\n",
        "with open(\"article.txt\", \"r\", encoding=\"utf8\") as f:\n",
        "    article_text = f.read()\n",
        "\n",
        "print(article_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQzLRwyCH42Q",
        "outputId": "4e065fd0-e7ab-4541-c8e6-5564e2cd5134"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "In recent news, technology companies are continuously advancing AI and machine learning.\n",
            "The development of new algorithms is transforming industries, from healthcare to finance.\n",
            "Companies like Google, Microsoft, and OpenAI are leading the charge in AI research, and\n",
            "the potential applications are vast.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTs-tEEUGyEl",
        "outputId": "f1b95063-202a-479b-a419-a48ab78efda1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Your max_length is set to 300, but your input_length is only 60. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The development of new algorithms is transforming industries, from healthcare to finance. Companies like Google, Microsoft, and OpenAI are leading the charge in AI research. The potential applications are vast, and are being explored by tech companies around the world. In recent news, technology companies are continuously advancing AI and machine learning. For more, visit CNN.com/ArtificialIntelligence. \n"
          ]
        }
      ],
      "source": [
        "import transformers\n",
        "from transformers import pipeline\n",
        "# Initialize the summarizer pipeline with a suitable model\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "# Read the article text from the file\n",
        "with open(\"article.txt\", \"r\", encoding=\"utf8\") as f:\n",
        "    article_text = f.read()\n",
        "\n",
        "# Check if the article is too long and split it into chunks if necessary\n",
        "max_input_length = 1024  # BART model's token limit\n",
        "\n",
        "# Split the article into smaller chunks if it's too long\n",
        "chunks = [article_text[i:i + max_input_length] for i in range(0, len(article_text), max_input_length)]\n",
        "\n",
        "# Summarize each chunk and combine the results\n",
        "summarized_text = \"\"\n",
        "for chunk in chunks:\n",
        "    summarized_chunk = summarizer(chunk, min_length=75, max_length=300)\n",
        "    summarized_text += summarized_chunk[0]['summary_text'] + \" \"\n",
        "\n",
        "# Print the summarized text\n",
        "print(summarized_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6vXP3W4_H0Lm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}